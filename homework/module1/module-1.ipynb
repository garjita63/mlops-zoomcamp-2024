{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ece64282-64c1-4aba-88df-605fdd765f8e",
   "metadata": {},
   "source": [
    "# Homework \n",
    "\n",
    "The goal of this homework is to train a simple model for predicting the duration of a ride - similar to what we did in this module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c314aee4-34ca-4116-a55d-5a8cb5453287",
   "metadata": {},
   "source": [
    "## Q1. Downloading the data\n",
    "\n",
    "We'll use the same NYC taxi dataset, but instead of \"Green Taxi Trip Records\", we'll use \"Yellow Taxi Trip Records\".\n",
    "\n",
    "Download the data for January and February 2023.\n",
    "\n",
    "Read the data for January. How many columns are there?\n",
    "\n",
    "- 16\n",
    "- 17\n",
    "- 18\n",
    "- 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cff0a2-a4e7-49ae-acae-476e107c1d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171aadac-019d-4d59-b064-fa271d49aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for January 2023\n",
    "url_january = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet'\n",
    "df_january = pd.read_parquet(url_january)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c4be0-5715-4dd3-b50d-d66c412df1e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_january"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a895c3a5-d2ba-4472-86e5-323518e457d7",
   "metadata": {},
   "source": [
    "### Answer Q1 : 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55686747-4aca-465f-8e44-94641ad38672",
   "metadata": {},
   "source": [
    "## Q2. Computing duration\n",
    "\n",
    "Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "\n",
    "What's the standard deviation of the trips duration in January?\n",
    "\n",
    "- 32.59\n",
    "- 42.59\n",
    "- 52.59\n",
    "- 62.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe2af03-c155-40a5-8f9c-f74e505c051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_january.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58c4e90-c049-41a5-b111-707fe0b86db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The columns 'tpep_pickup_datetime' and 'tpep_dropoff_datetime' are required to calculate the duration\n",
    "\n",
    "if 'tpep_pickup_datetime' in df_january.columns and 'tpep_dropoff_datetime' in df_january.columns:\n",
    "    # Compute the duration in minutes\n",
    "    df_january['duration'] = (df_january['tpep_dropoff_datetime'] - df_january['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "    # Compute the standard deviation of the duration\n",
    "    std_dev_duration = round(np.std(df_january['duration']), 2)\n",
    "\n",
    "    print(\"Standard Deviation of Trip Durations in January 2023:\", std_dev_duration)\n",
    "else:\n",
    "    print(\"The necessary columns are not present in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fff2ba-ea5e-410b-9227-cacc90e8c509",
   "metadata": {},
   "source": [
    "### Answer Q2 : 42.59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f5de1-737b-4bd7-a2e9-24a15143c48b",
   "metadata": {},
   "source": [
    "## Q3. Dropping outliers\n",
    "\n",
    "Next, we need to check the distribution of the duration variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "- 90%\n",
    "- 92%\n",
    "- 95%\n",
    "- 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbdbb57-02a1-4deb-9dc7-f4464e92c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the duration in minutes\n",
    "df_january['duration'] = (df_january['tpep_dropoff_datetime'] - df_january['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "# Filter the records to keep only those with duration between 1 and 60 minutes (inclusive)\n",
    "df_filtered = df_january[(df_january['duration'] >= 1) & (df_january['duration'] <= 60)]\n",
    "\n",
    "# Calculate the fraction of records left\n",
    "fraction_left = round(len(df_filtered) / len(df_january), 2)\n",
    "\n",
    "print(\"Fraction of records left after dropping outliers:\", int(fraction_left * 100), \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caf715d-0409-472d-8060-4812817573f0",
   "metadata": {},
   "source": [
    "### Answer Q3 : 98%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f18d467-68f1-4314-9623-4ae1d910f36d",
   "metadata": {},
   "source": [
    "## Q4. One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "- Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will label encode them)\n",
    "- Fit a dictionary vectorizer\n",
    "- Get a feature matrix from it\n",
    "  \n",
    "What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "- 2\n",
    "- 155\n",
    "- 345\n",
    "- 515\n",
    "- 715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c9dd2-9211-491b-a561-31405e9c78e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Assume df_filtered is already defined and filtered\n",
    "# Ensure the columns are of integer type first (if they aren't already)\n",
    "df_filtered.loc[:, 'PULocationID'] = df_filtered['PULocationID'].astype(int)\n",
    "df_filtered.loc[:, 'DOLocationID'] = df_filtered['DOLocationID'].astype(int)\n",
    "\n",
    "# Create a copy of the DataFrame and convert IDs to strings in the new DataFrame\n",
    "df_filtered_str = df_filtered.copy()\n",
    "df_filtered_str.loc[:, 'PULocationID'] = df_filtered_str['PULocationID'].astype(str)\n",
    "df_filtered_str.loc[:, 'DOLocationID'] = df_filtered_str['DOLocationID'].astype(str)\n",
    "\n",
    "# Turn the DataFrame into a list of dictionaries\n",
    "dicts = df_filtered_str[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "\n",
    "# Fit a dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "X = dv.fit_transform(dicts)\n",
    "\n",
    "# Get the dimensionality of the feature matrix\n",
    "print(\"Dimensionality of the feature matrix (number of columns):\", X.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b2afdc-9169-464e-8642-7dbb64f9dc59",
   "metadata": {},
   "source": [
    "### Answer Q4 : 515"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525ee52a-5373-49ef-9c97-4a67f6101e1b",
   "metadata": {},
   "source": [
    "## Q5. Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "- Train a plain linear regression model with default parameters\n",
    "- Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n",
    "- 3.64\n",
    "- 7.64\n",
    "- 11.64\n",
    "- 16.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd9ab3-0f69-4057-a923-02c9be2beb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Fit a dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(dicts)\n",
    "\n",
    "# Prepare the target variable\n",
    "y_train = df_filtered['duration'].values\n",
    "\n",
    "# Train a linear regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "# Calculate the RMSE on the training data\n",
    "rmse = round(np.sqrt(mean_squared_error(y_train, y_pred)), 2)\n",
    "print(\"RMSE on training data:\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06309025-0e2b-4c68-a04a-d0cab6f8295d",
   "metadata": {},
   "source": [
    "### Answer Q5 : 7.64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025e0aa-589d-4eeb-9498-9fa7c40b0133",
   "metadata": {},
   "source": [
    "## Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (February 2023).\n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "- 3.81\n",
    "- 7.81\n",
    "- 11.81\n",
    "- 16.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba81b9a-5ab9-459b-9329-97670e556727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the data for January 2023\n",
    "url_january = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet'\n",
    "df_january = pd.read_parquet(url_january)\n",
    "\n",
    "# Compute the duration in minutes\n",
    "df_january['duration'] = (df_january['tpep_dropoff_datetime'] - df_january['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "# Filter the records to keep only those with duration between 1 and 60 minutes (inclusive)\n",
    "df_filtered = df_january[(df_january['duration'] >= 1) & (df_january['duration'] <= 60)].copy()\n",
    "\n",
    "# Cast IDs to string after ensuring they are of object type\n",
    "df_filtered['PULocationID'] = df_filtered['PULocationID'].astype('object').astype(str)\n",
    "df_filtered['DOLocationID'] = df_filtered['DOLocationID'].astype('object').astype(str)\n",
    "\n",
    "# Turn the DataFrame into a list of dictionaries\n",
    "dicts = df_filtered[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "\n",
    "# Fit a dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(dicts)\n",
    "\n",
    "# Prepare the target variable\n",
    "y_train = df_filtered['duration'].values\n",
    "\n",
    "# Train a linear regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Load the data for February 2023\n",
    "url_february = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet'\n",
    "df_february = pd.read_parquet(url_february)\n",
    "\n",
    "# Compute the duration in minutes\n",
    "df_february['duration'] = (df_february['tpep_dropoff_datetime'] - df_february['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "# Filter the records to keep only those with duration between 1 and 60 minutes (inclusive)\n",
    "df_feb_filtered = df_february[(df_february['duration'] >= 1) & (df_february['duration'] <= 60)].copy()\n",
    "\n",
    "# Cast IDs to string after ensuring they are of object type\n",
    "df_feb_filtered['PULocationID'] = df_feb_filtered['PULocationID'].astype('object').astype(str)\n",
    "df_feb_filtered['DOLocationID'] = df_feb_filtered['DOLocationID'].astype('object').astype(str)\n",
    "\n",
    "# Turn the DataFrame into a list of dictionaries\n",
    "dicts_feb = df_feb_filtered[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "\n",
    "# Transform the validation data using the same dictionary vectorizer\n",
    "X_val = dv.transform(dicts_feb)\n",
    "\n",
    "# Prepare the target variable for the validation data\n",
    "y_val = df_feb_filtered['duration'].values\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_pred_val = lr.predict(X_val)\n",
    "\n",
    "# Calculate the RMSE on the validation data\n",
    "rmse_val = round(np.sqrt(mean_squared_error(y_val, y_pred_val)), 2)\n",
    "print(\"RMSE on validation data:\", rmse_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7512ed91-299f-49a0-9c5e-c48645014b4f",
   "metadata": {},
   "source": [
    "### Answer Q6 : 7.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4059112b-416d-4cfd-a7de-a99aba5f6e22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 5
}
